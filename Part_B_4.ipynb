{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp6KAX1UXqaK"
   },
   "source": [
    "# Question B4 (10 marks)\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsfKoCAMj9uo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjdf67uIarDX"
   },
   "source": [
    "Your co-investigators used a linear regression model to rapidly test out several combinations of train/test splits and shared with you their findings in a brief report attached in Appendix A below. You wish to investigate whether your deep learning model corroborates with their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M3-BW2LW4Icq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alibi-detect\n",
      "  Downloading alibi_detect-0.12.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (2.2.2)\n",
      "Requirement already satisfied: Pillow<11.0.0,>=5.4.1 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (10.4.0)\n",
      "Collecting opencv-python<5.0.0,>=3.2.0 (from alibi-detect)\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (1.12.0)\n",
      "Collecting scikit-image<0.23,>=0.19 (from alibi-detect)\n",
      "  Downloading scikit_image-0.22.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (1.5.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (4.45.2)\n",
      "Collecting dill<0.4.0,>=0.3.0 (from alibi-detect)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (2.32.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.8.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (2.9.2)\n",
      "Collecting toml<1.0.0,>=0.10.1 (from alibi-detect)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (2.0.10)\n",
      "Collecting numba!=0.54.0,<0.60.0,>=0.50.0 (from alibi-detect)\n",
      "  Downloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from alibi-detect) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.9.0.post0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba!=0.54.0,<0.60.0,>=0.50.0->alibi-detect)\n",
      "  Downloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.12/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.3)\n",
      "Collecting imageio>=2.27 (from scikit-image<0.23,>=0.19->alibi-detect)\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.23,>=0.19->alibi-detect)\n",
      "  Downloading tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image<0.23,>=0.19->alibi-detect)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<5.0.0,>=4.0.0->alibi-detect) (2024.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.16.0)\n",
      "Downloading alibi_detect-0.12.0-py3-none-any.whl (381 kB)\n",
      "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Downloading numba-0.59.1-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.22.0-cp312-cp312-macosx_12_0_arm64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading llvmlite-0.42.0-cp312-cp312-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Installing collected packages: toml, tifffile, opencv-python, llvmlite, lazy_loader, imageio, dill, scikit-image, numba, alibi-detect\n",
      "Successfully installed alibi-detect-0.12.0 dill-0.3.9 imageio-2.35.1 lazy_loader-0.4 llvmlite-0.42.0 numba-0.59.1 opencv-python-4.10.0.84 scikit-image-0.22.0 tifffile-2024.9.20 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7dD3Ihi4GF9"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJjXNMOqcHVJ"
   },
   "source": [
    "1.Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOUcXL5OXASY"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "import pytorch_tabular\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = pytorch_tabular.tabular_model.TabularModel.load_model('saved_models/b1')\n",
    "\n",
    "test_data = df[df['year'] == 2022]\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsbs0iMiaUy-"
   },
   "source": [
    "2.Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4FLRQfBaRS-"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here\n",
    "test_data = df[df['year'] == 2023]\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11mU8sxcaSAP"
   },
   "source": [
    "3.Did model degradation occur for the deep learning model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nviGacm6aSlf"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyiP8gBAcABD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruldtSTDcYzt"
   },
   "source": [
    "4.Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2019 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nGbdZc3ocYbB"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "target = [\"resale_price\"]\n",
    "categorical_cols = [\"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n",
    "continuous_cols = [\n",
    "    \"dist_to_nearest_stn\",\n",
    "    \"dist_to_dhoby\",\n",
    "    \"degree_centrality\",\n",
    "    \"eigenvector_centrality\",\n",
    "    \"remaining_lease_years\",\n",
    "    \"floor_area_sqm\",\n",
    "]\n",
    "\n",
    "# Extract unique categories for each categorical column\n",
    "category_map = {}\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    category_map[i] = df[col].unique().tolist()\n",
    "\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "\n",
    "X_train = df[df[\"year\"] <= 2019]\n",
    "X_test = df[df[\"year\"] == 2023]\n",
    "\n",
    "X_train = X_train[:n_train] # Sample from the dataset\n",
    "X_test = X_test[:n_test] # Sample from the dataset\n",
    "\n",
    "X_ref = X_train[categorical_cols + continuous_cols].values\n",
    "X_test = X_test[categorical_cols + continuous_cols].values\n",
    "\n",
    "y_ref = X_train[target].values\n",
    "y_test = df[df[\"year\"] == 2023][target].values[:n_test]\n",
    "\n",
    "categories_per_feature = {f: None for f in list(category_map.keys())}\n",
    "cd = TabularDrift(\n",
    "    X_ref, p_val=0.05, categories_per_feature=categories_per_feature\n",
    ")\n",
    "\n",
    "predictions = cd.predict(X_test)\n",
    "labels = ['No','Yes']\n",
    "print('Drift? {}'.format(labels[predictions['data']['is_drift']]))\n",
    "\n",
    "fpreds = cd.predict(X_test, drift_type='feature')\n",
    "feature_names = categorical_cols + continuous_cols\n",
    "\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmj3qq3PkJUf"
   },
   "source": [
    "5.Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5UOsX4JqkZ9S"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "Concept Drift. If the housing measures change the relationship between all the features and the resale_price, this would impact the conditions by which X impacts Y, thereby changing P(Y|X). Hence, despite the fact that our input features selected (X) for the model did not change, changes in the 'conditions' of the housing market still impact the resale price (Y) of the house. Thereby reflecting a case of Concept Drift which possibly led to model degradation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM2OoOJdkZj1"
   },
   "source": [
    "6.From your analysis via TabularDrift, which features contribute to this shift?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V3licBjskdLL"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "[\n",
    "    \"town\",\n",
    "    \"flat_model_type\",\n",
    "    \"storey_range\",\n",
    "    \"dist_to_dhoby\",\n",
    "    \"eigenvector_centrality\",\n",
    "    \"remaining_lease_years\",\n",
    "    \"floor_area_sqm\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB3fSvKskhEJ"
   },
   "source": [
    "7.Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqFinZObcYXu"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# We can try to train the model on the reference year in appendix A where the\n",
    "# data is likely representative of the data in 2023.\n",
    "model.fit(train=df[(df['year'] >= 2022) & (df['year'] < 2023)])\n",
    "\n",
    "test_data = df[df['year'] == 2023]\n",
    "\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQG9hZvAaq5g"
   },
   "source": [
    "### Appendix A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ARi2OxbDuZ"
   },
   "source": [
    "Here are our results from a linear regression model. We used StandardScaler for continuous variables and OneHotEncoder for categorical variables.\n",
    "\n",
    "While 2021 data can be predicted well, test R2 dropped rapidly for 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| Year <= 2020 | 2021     | 0.76    |\n",
    "| Year <= 2020 | **2022**     | 0.41    |\n",
    "| Year <= 2020 | **2023**     | **0.10**   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmv91FqgbI8h"
   },
   "source": [
    "Similarly, a model trained on 2017 data can predict 2018-2021 well (with slight degradation in performance for 2021), but drops drastically in 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2017         | 2018     | 0.90    |\n",
    "|              | 2019     | 0.89    |\n",
    "|              | 2020     | 0.87    |\n",
    "|              | 2021     | 0.72    |\n",
    "|              | **2022**     | **0.37**    |\n",
    "|              | **2023**     | **0.09**    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayKGs106bI6S"
   },
   "source": [
    "With the test set fixed at year 2021, training on data from 2017-2020 still works well on the test data, with minimal degradation. Training sets closer to year 2021 generally do better.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2020         | 2021     | 0.81    |\n",
    "| 2019         | 2021     | 0.75    |\n",
    "| 2018         | 2021     | 0.73    |\n",
    "| 2017         | 2021     | 0.72    |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWUKTcEICJ0j/YcXkGkr53",
   "collapsed_sections": [
    "wQG9hZvAaq5g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
