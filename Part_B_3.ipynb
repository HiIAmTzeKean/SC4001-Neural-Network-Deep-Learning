{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDDK5s1_mFRg"
   },
   "source": [
    "# Question B3 (10 marks)\n",
    "\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7WFI5tMpqGc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRCFpMEd3w8W"
   },
   "outputs": [],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utC2haR03sQY"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from captum.attr import Saliency, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUU-C3eRmWeE"
   },
   "source": [
    "1.First, load the dataset following the splits in Question B1. To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Do not standardise the numerical features for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNtpumjamL1N"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "train_data = df[df['year'] <= 2019]\n",
    "validation_data = df[df['year'] == 2020]\n",
    "test_data = df[df['year'] == 2021]\n",
    "\n",
    "# Drop all categorical features\n",
    "target = ['resale_price']\n",
    "continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "categorical_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "\n",
    "train_data = train_data[continuous_cols + target]\n",
    "validation_data = validation_data[continuous_cols + target]\n",
    "test_data = test_data[continuous_cols + target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4L7QdqLmX2s"
   },
   "source": [
    "2.Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Saliency, Input x Gradients, Integrated Gradients, GradientSHAP, Feature Ablation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGIWUq9Fmct8"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "size_hidden1 = 5\n",
    "size_hidden2 = 5\n",
    "size_hidden3 = 5\n",
    "no_labels = 1\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert dataframes to PyTorch tensors\n",
    "X_train = torch.tensor(train_data[continuous_cols].values).float()\n",
    "y_train = torch.tensor(train_data[target].values).view(-1, 1).float()\n",
    "\n",
    "X_val = torch.tensor(validation_data[continuous_cols].values).float()\n",
    "y_val = torch.tensor(validation_data[target].values).view(-1, 1).float()\n",
    "\n",
    "X_test = torch.tensor(test_data[continuous_cols].values).float()\n",
    "y_test = torch.tensor(test_data[target].values).view(-1, 1).float()\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDBResaleModel(nn.Module):\n",
    "    def __init__(self, no_features, no_hidden1, no_hidden2, no_hidden3, no_labels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(no_features, no_hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(no_hidden1, no_hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(no_hidden2, no_hidden3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.lin4 = nn.Linear(no_hidden3, no_labels)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.lin4(self.relu3(self.lin3(self.relu2(self.lin2(self.relu1(self.lin1(input)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HDBResaleModel(X_train.shape[1], size_hidden1, size_hidden2, size_hidden3, no_labels)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_inp, num_epochs, optimizer, loss_fn, dataloader):\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            # forward pass\n",
    "            outputs = model_inp(inputs)\n",
    "            # defining loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # accumulating running loss\n",
    "            running_loss += loss.item()\n",
    "            # updated weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        if epoch % 20 == 0:    \n",
    "            print('Epoch [%d]/[%d] running accumulative loss across all batches: %.3f' %\n",
    "                  (epoch + 1, num_epochs, running_loss))\n",
    "        running_loss = 0.0\n",
    "\n",
    "train(model, num_epochs, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Saliency, Input x Gradients, Integrated Gradients, GradientSHAP, Feature Ablation\n",
    "\n",
    "sal = Saliency(model)\n",
    "ixg = InputXGradient(model)\n",
    "ig = IntegratedGradients(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "sal_attr_test = sal.attribute(X_test[:1000])\n",
    "ixg_attr_test = ixg.attribute(X_test[:1000])\n",
    "ig_attr_test = ig.attribute(X_test[:1000], n_steps=50)\n",
    "\n",
    "# Entire training set used for the distribution of baselines\n",
    "\n",
    "gs_attr_test = gs.attribute(X_test[:1000], X_train)\n",
    "fa_attr_test = fa.attribute(X_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = train_data.drop(target, axis=1).columns\n",
    "\n",
    "x_axis_data = np.arange(X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: feature_names[idx], x_axis_data))\n",
    "\n",
    "sal_attr_test_sum = sal_attr_test.detach().numpy().sum(0)\n",
    "sal_attr_test_norm_sum = sal_attr_test_sum / np.linalg.norm(sal_attr_test_sum, ord=1)\n",
    "\n",
    "ixg_attr_test_sum = ixg_attr_test.detach().numpy().sum(0)\n",
    "ixg_attr_test_norm_sum = ixg_attr_test_sum / np.linalg.norm(ixg_attr_test_sum, ord=1)\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)\n",
    "gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum, ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['Saliency','Input x Gradients', 'Integrated Gradients', 'GradientSHAP', 'Feature Ablation']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, sal_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5a142')\n",
    "ax.bar(x_axis_data + width, ixg_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5428d')\n",
    "ax.bar(x_axis_data + 2 * width, ig_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + 3 * width, gs_attr_test_norm_sum, width, align='center',  alpha=0.8, color='#4260f5')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DexR-OzAmd26"
   },
   "source": [
    "3.Train a separate model with the same configuration but now standardise the features via **StandardScaler** (fit to training set, then transform all). State your observations with respect to GradientShap and explain why it has occurred.\n",
    "(Hint: Many gradient-based approaches depend on a baseline, which is an important choice to be made. Check the default baseline settings carefully.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzRk02TnmgyB"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_train = torch.tensor(scaled_X_train).float() # fixed typo\n",
    "\n",
    "scaled_X_val = scaler.transform(X_val)\n",
    "scaled_X_val = torch.tensor(scaled_X_val).float()\n",
    "\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "scaled_X_test = torch.tensor(scaled_X_test).float()\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(scaled_X_train, y_train)\n",
    "val_dataset = TensorDataset(scaled_X_val, y_val)\n",
    "test_dataset = TensorDataset(scaled_X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = HDBResaleModel(scaled_X_train.shape[1], size_hidden1, size_hidden2, size_hidden3, no_labels)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, num_epochs, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = Saliency(model)\n",
    "ixg = InputXGradient(model)\n",
    "ig = IntegratedGradients(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "sal_attr_test = sal.attribute(X_test[:1000])\n",
    "ixg_attr_test = ixg.attribute(X_test[:1000])\n",
    "ig_attr_test = ig.attribute(X_test[:1000], n_steps=50)\n",
    "gs_attr_test = gs.attribute(X_test[:1000], X_train)\n",
    "fa_attr_test = fa.attribute(X_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_names = train_data.drop(target, axis=1).columns\n",
    "\n",
    "x_axis_data = np.arange(X_test.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: feature_names[idx], x_axis_data))\n",
    "\n",
    "sal_attr_test_sum = sal_attr_test.detach().numpy().sum(0)\n",
    "sal_attr_test_norm_sum = sal_attr_test_sum / np.linalg.norm(sal_attr_test_sum, ord=1)\n",
    "\n",
    "ixg_attr_test_sum = ixg_attr_test.detach().numpy().sum(0)\n",
    "ixg_attr_test_norm_sum = ixg_attr_test_sum / np.linalg.norm(ixg_attr_test_sum, ord=1)\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)\n",
    "gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum, ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['Saliency','Input x Gradients', 'Integrated Gradients', 'GradientSHAP', 'Feature Ablation']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE)            # fontsize of the text sizes\n",
    "plt.rc('axes', titlesize=FONT_SIZE)       # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=FONT_SIZE)       # fontsize of the x and y labels\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)  # fontsize of the legend\n",
    "\n",
    "ax.bar(x_axis_data, sal_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5a142')\n",
    "ax.bar(x_axis_data + width, ixg_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5428d')\n",
    "ax.bar(x_axis_data + 2 * width, ig_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + 3 * width, gs_attr_test_norm_sum, width, align='center',  alpha=0.8, color='#4260f5')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Key Observations:\n",
    "- GradientSHAP attribution scores remain directionally consistent after feature scaling.\n",
    "- The magnitude of certain attribution scores (e.g., 'dist_to_dhoby') decreased, while others (e.g., 'remaining_lease_years' and 'floor_area_sqm') increased.\n",
    "- Feature scaling using StandardScaler changes the input distribution, affecting the baseline used by GradientSHAP.\n",
    "\n",
    "Explanation:\n",
    "Baseline Dependence: GradientSHAP's attribution scores are calculated relative to a baseline. By standardizing the features, you effectively change the input distribution, which in turn alters the baseline used by GradientSHAP. This can lead to changes in the magnitude of the attribution scores.\n",
    "Feature Sensitivity: The sensitivity of a feature to the model's output can be affected by its distribution. If a feature becomes more or less spread out after scaling, it may have a greater or lesser impact on the model's predictions, leading to corresponding changes in the attribution scores.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX9iqK6SmhQ5"
   },
   "source": [
    "Read https://distill.pub/2020/attribution-baselines/ to build up your understanding of Integrated Gradients (IG). Reading the sections before the section on ‘Game Theory and Missingness’ will be sufficient. Keep in mind that this article mainly focuses on classification problems. You might find the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum useful as well.\n",
    "\n",
    "\n",
    "Then, answer the following questions in the context of our dataset:\n",
    "\n",
    "4.Why did Saliency produce scores similar to IG?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67WqoEltmlRb"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "Key Observations:\n",
    "\n",
    "- Saliency and IG produce different scores for the same features, even when trained on scaled or non-scaled datasets.\n",
    "- The similarity between Saliency and IG depends on the consistency of gradients along the baseline-to-input path.\n",
    "- A baseline set to zero might be distant from the input distribution for certain features, leading to discrepancies in attribution scores.\n",
    "- Scaling the dataset can reduce the discrepancy between Saliency and IG values, possibly due to bringing the baseline closer to the input distribution.\n",
    "- IG's ability to capture non-linear relationships can contribute to the discrepancy, as it may assign higher importance to features that have a disproportionate impact on the output.\n",
    "\n",
    "Potential Explanations and Further Exploration:\n",
    "Data-Driven Baselines: Consider using data-driven baselines (e.g., mean or median of the input distribution) to ensure a more representative baseline for all features.\n",
    "Feature-Specific Baselines: Experiment with feature-specific baselines to account for differences in feature distributions.\n",
    "Feature Interactions: Explore feature interactions that might be missed by Saliency but captured by IG.\n",
    "Feature Engineering: Consider creating new features that capture non-linear relationships more effectively.\n",
    "Larger Datasets: Investigate if increasing the dataset size can help reduce the discrepancy between Saliency and IG, as a larger dataset might provide a more representative distribution.\n",
    "Model Complexity: Evaluate if the complexity of the model (e.g., number of layers, hidden units) affects the discrepancy. A more complex model might be better able to capture non-linear relationships.\n",
    "Different Scaling Methods: Experiment with different scaling methods (e.g., min-max normalization, standardization) to see if they have a significant impact on the discrepancy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYpfn3nCml1K"
   },
   "source": [
    "5.Why did Input x Gradients give the same attribution scores as IG?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5OmMEdMmnP_"
   },
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "Key Observations:\n",
    "- Both Input x Gradients and Integrated Gradients provide similar attribution scores, but there are noticeable differences.\n",
    "- A small difference between the baseline and input might lead to less variation in gradients, resulting in minimal differences between the two methods.\n",
    "- Scaling the dataset can further reduce the discrepancy between Input x Gradients and Integrated Gradients, likely due to bringing the baseline closer to the input distribution.\n",
    "\n",
    "Potential Explanations:\n",
    "Gradient Consistency: If the gradients are relatively consistent along the baseline-to-input path, the integral in Integrated Gradients might not significantly deviate from the direct gradient calculation in Input x Gradients. This could explain the similarity in their results.\n",
    "Scaling Effect: Scaling the dataset can standardize the input distribution, making the baseline more representative. This might reduce the impact of the baseline-input difference on the gradient calculations.\n",
    "Model Complexity: The complexity of the model (e.g., number of layers, hidden units) can also influence the similarity between Input x Gradients and Integrated Gradients. A simpler model might have more linear relationships, making the gradients more consistent.\n",
    "Feature Interactions: Complex feature interactions might be better captured by Integrated Gradients, leading to slightly different attribution scores compared to Input x Gradients.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
